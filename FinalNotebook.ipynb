{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Seven: Convolutional Neural Networks (CNN's)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Austin Chen, Luke Hansen, Oscar Vallner*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report, we will be returning to the CIFAR-10 dataset from our lab 3 report, a dataset consisting of 50,0000 32px x 32px images. Within these 50,000 images, there are 10 unique classes with 5,000 images each. From the <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">dataset's website</a>, the classification guide is as follows:\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"dataset_overview.png\" width=\"475px\" >\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there are 10 unique classifications within our image dataset, the CIFAR-10 dataset is merely a small labelled subset of the <a href=\"http://groups.csail.mit.edu/vision/TinyImages/\">80 million tiny images</a> dataset, a far larger collection of images. The \"80 million tiny images\" dataset was formed as a part of a large public initiative to form an expansive and accurate visual dictionary to aid the field of computer image recognition. The dataset now contains a visualization of 53,464 English nouns arranged by meaning, and this data was collected by scraping millions of images from all across the web.\n",
    "\n",
    "\n",
    "### _But why is all this data practical?_\n",
    "\n",
    "In the ever-growing field of AI advancement, image recognition is paramount. While there already exists several examples of applied image recognition in industry (such as face detection and AI), a more comprehensive and sophisticated AI would have to leverage broader machine learning image recognition algorithms in order to expand beyond these narrow applications.\n",
    "\n",
    "According to the dataset's website:\n",
    "\n",
    "_\"computers have difficulty recognizing objects in images. While practical solutions exist for a few simple classes such as human faces or cars, the more general problem of recognizing all different classes of objects in the world (e.g. guitars, bottles, telephones) remains unsolved.\"_\n",
    "\n",
    "\n",
    "At Facebook's 2016 annual developer conference, Mark Zuckerberg outlined the social network's AI plans to \"build systems that are better than people at perception: seeing, hearing, language, and so on.‚Äù Even these specific plans justify the importance of having so much image data in the first place. For example, image recognition technology catered to the blind, can \"see\" what is going on in a picture and explain it out loud (in fact, Facebook has been working on such accessibility features like this). Promoting technology usage for the visually impaired is a noble use case of image classification, expanding the tools of technology to all. \n",
    "\n",
    "No matter the application, maintaining an extensive catalogue of images has endless applications. Though it may not seem practical in the present, the there are effectively an infinite number of possible images a visual system can be confronted with, and an infinite set of applications it can be helpful for. \n",
    "\n",
    "\n",
    "### The CIFAR-10 Subset\n",
    "\n",
    "Focusing back in on the CIFAR-10 dataset, we will be narrowing the focus of our classification problem. When looking at the image categories, the two most compelling categories that stood out to us were automobiles and deer. \n",
    "\n",
    "In 2017, one of the most relevant applications of image recognition falls under the transportation domain in the form self-driving/autonomous vehicles. One of the primary requirements of self-driving vehicles is to have accurate, live image recognition. In order for a self-driving car to be as safe as possible, it must be able to quickly classify objects and animals in the road just as well as humans can (if not better). In the United States, <a href=\"http://cultureofsafety.thesilverlining.com/driving/deer-vs-car-collisions\">the National Highway Safety Administration (NHSA) conducted a study</a> concerning the increasing dangers from deer-related vehicle accidents. Their findings are as follows:\n",
    "\n",
    "- There are approximately 1.5 million deer-related car accidents annually\n",
    "- The cost of these accidents results in over 1 billion dollars in vehicle damage\n",
    "- There are around 175-200 fatalities and 10,000 injuries every year\n",
    "\n",
    "The fact that deer collisions cause over 1 billion dollars worth of vehicle damage a year provides us with ample business incentive to create an accurate classification model. Once the additional monetary costs of fatalities and injuries are accounted for on top of the 1 billion, we have an even more compelling reason to create a classification model to resolve this issue. \n",
    "\n",
    "Therefore, for our classification problem, we will be attempting to create an image recognition model that can classify and distinguish incoming automobiles on the road from deer. If a car can determine if an oncoming object is a deer or a vehicle, it could automatically brake, potentially saving drivers from a fatal collision with a deer. Within the CIFAR-10 dataset, we will be taking all 5,000 images from the \"automobile\" category, and combining them with all 5,000 images from the \"trucks\" category to create an overarching \"vehicle\" category. We will then build a convolutional neural network that will distinguish between these road vehicles and deer. With a reliable enough model, our neural network would ideally be deployed in autonomous driving systems in consumer vehicles across America. \n",
    "\n",
    "Although we have mostly discussed autonomous vehicle deployment thus far, autonomous vehicles are still in development in 2017, and have a long ways before being perfected. A far more feasible intermediate deployment could be used in roadside cameras on highways. If a roadside camera setup detects that a deer is in the road, it can flash several bright warning lights to alert the drivers on the road. If the roadside camera only detects a car, it would not flash its lights. A reliable model could benefit several stakeholders, ranging from car manufacturers, to drivers, and even taxpayers in America who pay for road repairs that could be caused by deer related automobile collisions.\n",
    "\n",
    "\n",
    "## Measure of Success\n",
    "\n",
    "Our classification task is binary, and even if we use accuracy as our primary scoring metric we should aim for far higher than random chance, 50% (however, we won't use accuracy). We must remind ourselves that with our business case, lives are at risk. A roadside camera & light system should be as accurate as possible when determining when deer are obstructing the road. As we will discuss later, it might even be advantageous to analyze the implications of false positives and false negatives; that is, when the alert light would fires when there isn't actually a deer there, or if it fails to trigger when a deer is there.\n",
    "\n",
    "---\n",
    "\n",
    "Link to dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imshow\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using Keras with a TensorFlow backend. We are also importing our dataset from the Keras datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading our dataset and creating training and testing splits. The height and width of each image is (32x32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "y_train_labels = [class_labels[int(val)] for val in y_train]\n",
    "h = 32\n",
    "w = 32\n",
    "\n",
    "# For use later for printing out images\n",
    "examples_automobiles = []\n",
    "examples_deer = []\n",
    "\n",
    "for i in range (0, len(y_train)):\n",
    "    if y_train[i][0] == 1 or y_train[i][0] == 9:\n",
    "        examples_automobiles.append(X_train[i])\n",
    "    if y_train[i][0] == 4:\n",
    "        examples_deer.append(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to preprocess our images. We want to normalize and scale our images. We do this by scaling the pixel values to a range of -0.5 to 0.5. We accomplish this by dividing the pixel values by 255 to bring them to a range of 0-1, and subtracting 0.5 to bring the range to (-0.5, 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "X_train = X_train - 1/2\n",
    "X_test = X_test - 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we only care about three of the ten classes above: automobiles, trucks, and deer. We must create our binary classification by grouping automobiles and trucks together, creating an overall \"automobile\" class to compare to deer. We have decided to add the \"truck\" category to the automobile category because both trucks and normal cars are likely to be found on roads that are susceptible to deer collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes only the classes we are concerned with \n",
    "sub_sample = [1, 4, 9]\n",
    "X_sub_train = []\n",
    "y_sub_train = []\n",
    "for i in range(0,len(y_train)):\n",
    "    if y_train[i][0] in sub_sample:\n",
    "        X_sub_train.append(X_train[i])\n",
    "        if y_train[i][0] == 1 or y_train[i][0] == 9:\n",
    "            y_sub_train.append([0])\n",
    "        if y_train[i][0] == 4:\n",
    "            y_sub_train.append([1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better acclimate, here are some examples on what our automobile images look like. As a reminder, we have combined both the original 'trucks' category with the original 'automobile' category to create a new 'automobile' category.\n",
    "\n",
    "*Note: This is what the images look like before preprocessing and normalization.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imshow\n",
    "\n",
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.io import imshow\n",
    "import seaborn as sns\n",
    "%matplotlib inline       \n",
    "    \n",
    "n_row = 3\n",
    "n_column = 5\n",
    "        \n",
    "plt.figure(figsize=(2.5 * n_column, 3 * n_row))\n",
    "plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    \n",
    "\n",
    "for i in range(n_row * n_column):\n",
    "    plt.subplot(n_row, n_column, i + 1)\n",
    "    plt.imshow(examples_automobiles[i].squeeze())\n",
    "    plt.title(\"Automobiles\", size=13)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are examples of images in the 'deer' category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5 * n_column, 3 * n_row))\n",
    "plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    \n",
    "\n",
    "for i in range(n_row * n_column):\n",
    "    plt.subplot(n_row, n_column, i + 1)\n",
    "    plt.imshow(examples_deer[i].squeeze())\n",
    "    plt.title(\"Deer\", size=13)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sub_test = []\n",
    "y_sub_test = []\n",
    "for i in range(0,len(y_test)):\n",
    "    if y_test[i][0] in sub_sample:\n",
    "        X_sub_test.append(X_test[i])\n",
    "        # If it's a truck or automobile\n",
    "        if y_test[i][0] == 1 or y_test[i][0] == 9:\n",
    "            y_sub_test.append([0])\n",
    "        # If it's a deer\n",
    "        if y_test[i][0] == 4:\n",
    "            y_sub_test.append([1])\n",
    "\n",
    "X_sub_train = np.array(X_sub_train)\n",
    "X_sub_test = np.array(X_sub_test)\n",
    "y_sub_train = np.array(y_sub_train)\n",
    "y_sub_test = np.array(y_sub_test)\n",
    "        \n",
    "sub_class_labels = ['automobile', 'deer']\n",
    "y_sub_train_labels = [sub_class_labels[int(val)] for val in y_sub_train]\n",
    "\n",
    "NUM_CLASSES = len(sub_class_labels)\n",
    "y_sub_train_ohe = keras.utils.to_categorical(y_sub_train, NUM_CLASSES)\n",
    "y_sub_test_ohe = keras.utils.to_categorical(y_sub_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In determining the most important evaluation metric, it is important to reiterate the business case with our classification model. As we stated above, our binary classification problem, in a real world scenario, aims to identify whether objects on the road are a deer or an automobile. Given that information, we strongly believe that it is much safer to reduce the number of false negatives. Our data encoding sets automobiles/trucks to be equal to 0 (negative class) and deer to be 1 (positive class). Our confusion matrix is as follows:\n",
    "\n",
    "Deer vs. automobiles (trucks and automobiles)\n",
    "\n",
    "- True Positive: Classifies: Deer. Reality: Deer\n",
    "- False Positive: Classifies: Deer. Reality: Car\n",
    "- False Negative: Classifies: Car. Reality: Deer\n",
    "- True Negative: Classifies: Automobile. Reality: Automobile.\n",
    "\n",
    "Therefore, if we wish to minimize the number of false negatives, it would be the most appropriate to use the recall metric. The recall metric scores the model poorly if it classifies a deer (1) as a car(0). Because the business case exhibits the goal of reducing automobile collisions with deer, it would be bad to NOT warn motorists that there is a deer on the road, when in reality, there really is one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Cross Validation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our dataset, we narrowed down our cross validation techniques down to two: 10-fold cross validation and **stratified** 10-fold cross validation. However, we ultimately decided against a stratified cross validation. Here's why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.graph_objs import Figure, Scatter, Marker, Layout, XAxis, YAxis, Bar, Line\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "\n",
    "class_labels = ['Automobiles', 'Deer']\n",
    "\n",
    "graph1 = {'labels': class_labels,\n",
    "          'values': np.bincount(y_sub_train[:, 0]),\n",
    "            'type': 'pie'}\n",
    "fig = dict()\n",
    "fig['data'] = [graph1]\n",
    "fig['layout'] = {'title': 'Binary Class Distribution',\n",
    "                'autosize':False,\n",
    "                'width':500,\n",
    "                'height':300}\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the chart above, 66% of the instances in our dataset are automobiles, while 33% are deer. While there is a definitive class imbalance, here, we do not believe it is an extreme enough class imbalance to absolutely mandate a stratified cross validation. Our vehicle instances outnumber deer 2:1, but we have numerous instances of both classes, with 5,000 instances of deer (our lower represented class between the two). Perhaps, however, a class imbalance is actually advantageous for our classification model. \n",
    "\n",
    "If we step back and think about a real life scenario, many vehicle collisions with deer happen past sundown and at night, on lower traffic single/double lane highways (according to the NHSA study referenced above). And more often than not, these collisions only involve one car and one deer, as opposed to one car colliding with an entire herd of deer. Therefore, when considering our methods for cross validation, we must remember what is realistic in a real world scenario. In standard scenarios, automobiles outnumber deer--perhaps even more than 2:1 (our class balance).\n",
    "\n",
    "Therefore, while it might be nice to ensure equal class representation across all the folds, our goal is to use a cross-validation method that has a realistic mirroring of real world practice. We cannot guarantee that the ratio of cars to deer on the road will always be a set constant ratio, nor can we guarantee that a new batch of data that is fed into our classifier will containt he same ratio. We believe that stratifying our data might detract from a realistic mirroring.\n",
    "\n",
    "Therefore, we will be using 10-fold cross validation as our metric as opposed to stratified 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Convolutional Neural Network Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Network Architecture Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Performance Analysis Compared to Scikit-Learn MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
