{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yo this notebook is lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from skimage.io import imshow\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "y_train_labels = [class_labels[int(val)] for val in y_train]\n",
    "h = 32\n",
    "w = 32\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "X_train = X_train - 1/2\n",
    "X_test = X_test - 1/2\n",
    "\n",
    "# Takes only the classes we are concerned with \n",
    "sub_sample = [1, 4, 9]\n",
    "X_sub_train = []\n",
    "y_sub_train = []\n",
    "for i in range(0,len(y_train)):\n",
    "    if y_train[i][0] in sub_sample:\n",
    "        X_sub_train.append(X_train[i])\n",
    "        if y_train[i][0] == 1 or y_train[i][0] == 9:\n",
    "            y_sub_train.append([0])\n",
    "        if y_train[i][0] == 4:\n",
    "            y_sub_train.append([1])\n",
    "\n",
    "        \n",
    "X_sub_test = []\n",
    "y_sub_test = []\n",
    "for i in range(0,len(y_test)):\n",
    "    if y_test[i][0] in sub_sample:\n",
    "        X_sub_test.append(X_test[i])\n",
    "        # If it's a truck or automobile\n",
    "        if y_test[i][0] == 1 or y_test[i][0] == 9:\n",
    "            y_sub_test.append([0])\n",
    "        # If it's a deer\n",
    "        if y_test[i][0] == 4:\n",
    "            y_sub_test.append([1])\n",
    "\n",
    "X_sub_train = np.array(X_sub_train)\n",
    "X_sub_test = np.array(X_sub_test)\n",
    "y_sub_train = np.array(y_sub_train)\n",
    "y_sub_test = np.array(y_sub_test)\n",
    "        \n",
    "sub_class_labels = ['automobile', 'deer']\n",
    "y_sub_train_labels = [sub_class_labels[int(val)] for val in y_sub_train]\n",
    "\n",
    "NUM_CLASSES = len(sub_class_labels)\n",
    "y_sub_train_ohe = keras.utils.to_categorical(y_sub_train, NUM_CLASSES)\n",
    "y_sub_test_ohe = keras.utils.to_categorical(y_sub_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(X_sub_train)\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imshow(X_sub_train[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "15000\n",
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_sub_train))\n",
    "print(len(y_sub_train))\n",
    "print(len(X_sub_test))\n",
    "print(len(y_sub_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_c = np.concatenate([X_train,X_test], axis=0)\n",
    "#y_c = np.concatenate([y_train,y_test], axis=0).flatten()\n",
    "#vectorized_color = np.reshape(X_c,(len(X_c),32*32,3))\n",
    "#color_pixels = np.reshape(vectorized_color,(len(vectorized_color)*32*32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bw_pixels = [(0.21*pixel[0])+(0.72*pixel[1])+(0.07*pixel[2]) for pixel in color_pixels]#convert rgb to b/w\n",
    "#vectorized_bw = np.reshape(bw_pixels,(len(X),32*32))#reconstruct to list in image vectors\n",
    "#vectorized_bw.dump(\"data/vectorized_bw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vectorized_bw_all = np.load(\"data/vectorized_bw\")\\nprint(vectorized_bw_all.shape)\\n\\n#we might need these DF\\'s later\\ndf_bw = pd.DataFrame(data=vectorized_bw_all)\\ndf_bw = df_bw.assign(y=pd.Series(y,name=\\'y\\'))\\n#df_bw_sample = df_bw.sample(5000)\\nX = df_bw.drop(\\'y\\', axis=1).as_matrix()\\ny = df_bw.y.as_matrix()\\nprint(X.shape)\\nprint(y.shape)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''vectorized_bw_all = np.load(\"data/vectorized_bw\")\n",
    "print(vectorized_bw_all.shape)\n",
    "\n",
    "#we might need these DF's later\n",
    "df_bw = pd.DataFrame(data=vectorized_bw_all)\n",
    "df_bw = df_bw.assign(y=pd.Series(y,name='y'))\n",
    "#df_bw_sample = df_bw.sample(5000)\n",
    "X = df_bw.drop('y', axis=1).as_matrix()\n",
    "y = df_bw.y.as_matrix()\n",
    "print(X.shape)\n",
    "print(y.shape)'''\n",
    "#now, we can do cv or a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import average \n",
    "from keras.models import Input, Model\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN #1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.layers import average \n",
    "from keras.models import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "l2_lambda = 0.0001\n",
    "\n",
    "input_holder = Input(shape=(w, h, 3))\n",
    "conv1 = Conv2D(filters=32,\n",
    "               input_shape = (w,h,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu')(input_holder)\n",
    "\n",
    "max1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
    "\n",
    "conv2 = Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu')(max1)\n",
    "\n",
    "max2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
    "\n",
    "\n",
    "# add one layer on flattened output\n",
    "drop1 = Dropout(0.25)(max2) # add some dropout for regularization after conv layers\n",
    "flat1 = Flatten()(drop1)\n",
    "dense1 = Dense(128, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "            )(flat1)\n",
    "drop2 = Dropout(0.5)(dense1) # add some dropout for regularization, again!\n",
    "dense2_1 = Dense(NUM_CLASSES, \n",
    "              activation='sigmoid', \n",
    "              kernel_initializer='glorot_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "             )(drop2)\n",
    "\n",
    "cnn1 = Model(inputs=input_holder,outputs=dense2_1)\n",
    "\n",
    "# Let's train the model \n",
    "cnn1.compile(loss='binary_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "cnn1.fit(X_sub_train, y_sub_train_ohe,\n",
    "                      #steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn1.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN #1 with Data Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5, # used, Int. Degree range for random rotations.\n",
    "    width_shift_range=0.1, # used, Float (fraction of total width). Range for random horizontal shifts.\n",
    "    height_shift_range=0.1, # used,  Float (fraction of total height). Range for random vertical shifts.\n",
    "    shear_range=0., # Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_de = Model(inputs=input_holder,outputs=dense2_1)\n",
    "\n",
    "# Let's train the model \n",
    "cnn1_de.compile(loss='binary_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "datagen.fit(X_sub_train)\n",
    "cnn1_de.fit_generator(datagen.flow(X_sub_train, y_sub_train_ohe, batch_size=128), \n",
    "                      steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn1_de.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN #2: LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "l2_lambda = 0.0001\n",
    "input_holder = Input(shape=(w, h, 3))\n",
    "\n",
    "conv1 = Conv2D(filters=6,kernel_size=(5,5),\n",
    "               input_shape = (img_wh,img_wh,1), \n",
    "               padding='valid', \n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda))(input_holder)\n",
    "max1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
    "batch1 = BatchNormalization()(max1)\n",
    "activ1 = Activation(\"sigmoid\")(batch1)\n",
    "\n",
    "conv2 = Conv2D(filters=16,kernel_size=(5,5), \n",
    "               padding='valid', \n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda))(activ1)\n",
    "max2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
    "batch2 = BatchNormalization()(max2)\n",
    "activ2 = Activation(\"sigmoid\")(batch2)\n",
    "\n",
    "conv3 = Conv2D(filters=120,kernel_size=(1,1), \n",
    "               padding='valid', \n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda))(activ2)\n",
    "\n",
    "\n",
    "# add one layer on flattened output\n",
    "#drop1 = Dropout(0.25)(max2) # add some dropout for regularization after conv layers\n",
    "flat1 = Flatten()(conv3)\n",
    "dense1 = Dense(128, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "            )(flat1)\n",
    "drop2 = Dropout(0.5)(dense1) # add some dropout for regularization, again!\n",
    "dense2_2 = Dense(NUM_CLASSES, \n",
    "              activation='sigmoid', \n",
    "              kernel_initializer='glorot_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "             )(drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = Model(inputs=input_holder,outputs=dense2_2)\n",
    "\n",
    "# Let's train the model \n",
    "cnn2.compile(loss=w_categorical_crossentropy, # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "cnn2.fit(X_sub_train, y_sub_train_ohe,\n",
    "                      #steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn2.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN #2: LeNet5 with Data Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5, # used, Int. Degree range for random rotations.\n",
    "    width_shift_range=0.1, # used, Float (fraction of total width). Range for random horizontal shifts.\n",
    "    height_shift_range=0.1, # used,  Float (fraction of total height). Range for random vertical shifts.\n",
    "    shear_range=0., # Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_de = Model(inputs=input_holder,outputs=dense2_2)\n",
    "\n",
    "# Let's train the model \n",
    "cnn2_de.compile(loss='binary_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "datagen.fit(X_sub_train)\n",
    "cnn2_de.fit_generator(datagen.flow(X_sub_train, y_sub_train_ohe, batch_size=128), \n",
    "                      steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn2_de.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN #1 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.layers import average \n",
    "from keras.models import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "l2_lambda = 0.0001\n",
    "\n",
    "num_ensembles = 5\n",
    "\n",
    "input_holder = Input(shape=(w, h, 3))\n",
    "\n",
    "branches = []\n",
    "for _ in range(num_ensembles):\n",
    "\n",
    "    conv1 = Conv2D(filters=32,\n",
    "                   input_shape = (w,h,1),\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu')(input_holder)\n",
    "    \n",
    "    max1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters=32,\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu')(max1)\n",
    "    \n",
    "    max2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
    "\n",
    "\n",
    "    # add one layer on flattened output\n",
    "    drop1 = Dropout(0.25)(max2) # add some dropout for regularization after conv layers\n",
    "    flat1 = Flatten()(drop1)\n",
    "    dense1 = Dense(128, \n",
    "                  activation='relu',\n",
    "                  kernel_initializer='he_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                )(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1) # add some dropout for regularization, again!\n",
    "    dense2 = Dense(NUM_CLASSES, \n",
    "                  activation='sigmoid', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                 )(drop2)\n",
    "    \n",
    "    # now add this branch onto the master list\n",
    "    branches.append(dense2)\n",
    "\n",
    "# that's it, we just need to average the results\n",
    "ave1 = average(branches)\n",
    "\n",
    "# here is the secret sauce for setting the network using the \n",
    "#   Model API:\n",
    "cnn_ens1 = Model(inputs=input_holder,outputs=ave1)\n",
    "\n",
    "# Let's train the model \n",
    "cnn_ens1.compile(loss=w_categorical_crossentropy, # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "cnn_ens1.fit_generator(datagen.flow(X_sub_train, y_sub_train_ohe, batch_size=128), \n",
    "                      steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn_ens1.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn1.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKAY BOIS WE JUST TRYNA GET THAT CROSS VALIDATION WORKIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "58/58 [==============================] - 9s - loss: 0.4378 - acc: 0.8244 - val_loss: 0.2915 - val_acc: 0.8901\n",
      "Epoch 2/2\n",
      "58/58 [==============================] - 9s - loss: 0.3059 - acc: 0.8873 - val_loss: 0.2411 - val_acc: 0.9083\n",
      "Recall:  0.760625501203\n",
      "Accuracy:  0.9088\n",
      "-----------------------\n",
      "Epoch 1/2\n",
      "58/58 [==============================] - 9s - loss: 0.5115 - acc: 0.7808 - val_loss: 0.3229 - val_acc: 0.8858\n",
      "Epoch 2/2\n",
      "58/58 [==============================] - 8s - loss: 0.3518 - acc: 0.8663 - val_loss: 0.2459 - val_acc: 0.9173\n",
      "Recall:  0.852354349561\n",
      "Accuracy:  0.917866666667\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as mt\n",
    "from numpy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "l2_lambda = 0.0001\n",
    "\n",
    "#####Locus######\n",
    "mlp_roc_auc = []\n",
    "cnn_roc_auc = []\n",
    "mean_tpr_mlp = 0.0\n",
    "mean_fpr_mlp = np.linspace(0, 1, 100)\n",
    "mean_tpr_cnn = 0.0\n",
    "mean_fpr_cnn = np.linspace(0, 1, 100)\n",
    "#####Locus######\n",
    "\n",
    "num_folds = 2 #Locus\n",
    "model_list1 = []\n",
    "yhat_list1 = []\n",
    "y_test_list1 = []\n",
    "\n",
    "skf = KFold(n_splits=num_folds).split(X_sub_train, y_sub_train_ohe)\n",
    "for k, (train_indices, test_indices) in enumerate(skf):\n",
    "    cv_X_train = np.array(X_sub_train[train_indices])\n",
    "    cv_y_train = np.array(y_sub_train[train_indices])\n",
    "    cv_y_train_ohe = np.array(y_sub_train_ohe[train_indices])\n",
    "    \n",
    "    cv_X_test = np.array(X_sub_train[test_indices])\n",
    "    cv_y_test = np.array(y_sub_train[test_indices])\n",
    "    cv_y_test_ohe = np.array(y_sub_train_ohe[test_indices])\n",
    "    \n",
    "    \n",
    "    input_holder = Input(shape=(w, h, 3))\n",
    "    conv1 = Conv2D(filters=32,\n",
    "                   input_shape = (w,h,1),\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu')(input_holder)\n",
    "\n",
    "    max1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters=32,\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu')(max1)\n",
    "\n",
    "    max2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
    "\n",
    "\n",
    "    # add one layer on flattened output\n",
    "    drop1 = Dropout(0.25)(max2) # add some dropout for regularization after conv layers\n",
    "    flat1 = Flatten()(drop1)\n",
    "    dense1 = Dense(128, \n",
    "                  activation='relu',\n",
    "                  kernel_initializer='he_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                )(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1) # add some dropout for regularization, again!\n",
    "    dense2_1 = Dense(2, \n",
    "                  activation='sigmoid', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                 )(drop2)\n",
    "    cnn1_de = Model(inputs=input_holder,outputs=dense2_1)\n",
    "\n",
    "    # Let's train the model \n",
    "    cnn1_de.compile(loss='binary_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                    optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                    metrics=['accuracy'])\n",
    "    datagen.fit(cv_X_train)\n",
    "    cnn1_de.fit_generator(datagen.flow(cv_X_train, cv_y_train_ohe, batch_size=128), \n",
    "                          steps_per_epoch=int(len(cv_X_train)/128), # how many generators to go through per epoch\n",
    "                          epochs=2, verbose=1,\n",
    "                          validation_data=(cv_X_test, cv_y_test_ohe)\n",
    "                          #callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                         )\n",
    "    \n",
    "    yhat = np.argmax(cnn1_de.predict(cv_X_test), axis=1)\n",
    "    rec_cnn = mt.recall_score(cv_y_test,yhat)\n",
    "    acc_cnn = mt.accuracy_score(cv_y_test,yhat)\n",
    "    print(\"Recall: \", rec_cnn)\n",
    "    print(\"Accuracy: \", acc_cnn)\n",
    "    print(\"-----------------------\")\n",
    "    model_list1.append(cnn1_de)\n",
    "    yhat_list1.append(yhat)\n",
    "    y_test_list1.append(cv_y_test)\n",
    "    \n",
    "    \n",
    "    #####Locus######\n",
    "    probs_cnn = list(cnn1_de.predict(cv_X_test))\n",
    "    probs_cnn = np.array(probs_cnn)[:,1]\n",
    "    fpr_cnn, tpr_cnn, _ = roc_curve(cv_y_test, probs_cnn)\n",
    "    cnn_roc_auc.append((fpr_cnn, tpr_cnn, auc(fpr_cnn, tpr_cnn)))\n",
    "    mean_tpr_cnn += interp(mean_fpr_cnn, fpr_cnn, tpr_cnn)\n",
    "    mean_tpr_cnn[0] = 0.0   \n",
    "\n",
    "# TODO: uncomment when we add the MLP\n",
    "#     probs_mlp = mlp.predict_proba(X_test_mlp)\n",
    "#     probs_mlp = np.array(probs_mlp)[:,1]\n",
    "#     fpr_mlp, tpr_mlp, _ = roc_curve(y_test, probs_mlp)\n",
    "#     mlp_roc_auc.append((fpr_mlp, tpr_mlp, auc(fpr_mlp, tpr_mlp)))\n",
    "#     mean_tpr_mlp  += interp(mean_fpr_mlp, fpr_mlp, tpr_mlp)\n",
    "#     mean_tpr_mlp [0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment when we add the MLP\n",
    "# mean_tpr_mlp /= n_splits\n",
    "# mean_tpr_mlp[-1] = 1.0\n",
    "# mean_auc_mlp = auc(mean_fpr_mlp, mean_tpr_mlp)\n",
    "\n",
    "mean_tpr_cnn /= num_folds\n",
    "mean_tpr_cnn[-1] = 1.0\n",
    "mean_auc_cnn = auc(mean_fpr_cnn, mean_tpr_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159c8a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "i = 0\n",
    "for fpr, tpr, auc_ in cnn_roc_auc:\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve # %d (CNN) (area = %0.2f)' % (i, auc_))\n",
    "        i += 1\n",
    "# TODO: uncomment when we add the MLP\n",
    "# for fpr, tpr, auc_ in mlp_roc_auc:\n",
    "#         plt.plot(fpr, tpr, color='green',\n",
    "#              lw=lw, label='ROC curve # %d (MLP) (area = %0.2f)' % (i, auc_))\n",
    "#         i += 1        \n",
    "        \n",
    "# plt.plot(mean_fpr_mlp, mean_tpr_mlp, 'k--', label='mean ROC (MLP) (area = %0.2f)' % mean_auc_mlp, lw=2)\n",
    "plt.plot(mean_fpr_cnn, mean_tpr_cnn, 'k-', label='mean ROC (CNN) (area = %0.2f)' % mean_auc_cnn, lw=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Luke's\" loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import functools\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "weights=np.array([[1,0],[-1,1]])\n",
    "def w_categorical_crossentropy(y_true, y_pred):\n",
    "    nb_cl = len(weights)\n",
    "    final_mask = K.zeros_like(y_pred[:, 0])\n",
    "    y_pred_max = K.max(y_pred, axis=1)\n",
    "    y_pred_max = tf.expand_dims(y_pred_max, 1)\n",
    "    y_pred_max_mat = K.equal(y_pred, y_pred_max)\n",
    "    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n",
    "\n",
    "        final_mask += (K.cast(weights[c_t, c_p],K.floatx()) * K.cast(y_pred_max_mat[:, c_p] ,K.floatx())* K.cast(y_true[:, c_t],K.floatx()))\n",
    "    return K.categorical_crossentropy(y_pred, y_true) * final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.layers import average \n",
    "from keras.models import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "l2_lambda = 0.0001\n",
    "\n",
    "num_ensembles = 5\n",
    "\n",
    "input_holder = Input(shape=(w, h, 3))\n",
    "\n",
    "branches = []\n",
    "for _ in range(num_ensembles):\n",
    "\n",
    "    conv1 = Conv2D(filters=32,\n",
    "                   input_shape = (w,h,1),\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu')(input_holder)\n",
    "    \n",
    "    max1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters=32,\n",
    "                   kernel_size=(3,3),\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda),\n",
    "                   padding='same', \n",
    "                   activation='relu')(max1)\n",
    "    \n",
    "    max2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
    "\n",
    "\n",
    "    # add one layer on flattened output\n",
    "    drop1 = Dropout(0.25)(max2) # add some dropout for regularization after conv layers\n",
    "    flat1 = Flatten()(drop1)\n",
    "    dense1 = Dense(128, \n",
    "                  activation='relu',\n",
    "                  kernel_initializer='he_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                )(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1) # add some dropout for regularization, again!\n",
    "    dense2 = Dense(NUM_CLASSES, \n",
    "                  activation='sigmoid', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                 )(drop2)\n",
    "    \n",
    "    # now add this branch onto the master list\n",
    "    branches.append(dense2)\n",
    "\n",
    "# that's it, we just need to average the results\n",
    "ave = average(branches)\n",
    "\n",
    "# here is the secret sauce for setting the network using the \n",
    "#   Model API:\n",
    "cnn_ens2 = Model(inputs=input_holder,outputs=ave)\n",
    "\n",
    "# Let's train the model \n",
    "cnn_ens2.compile(loss='binary_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "cnn_ens2.fit_generator(datagen.flow(X_sub_train, y_sub_train_ohe, batch_size=128), \n",
    "                      steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "yhat_cnn = np.argmax(cnn_ens.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cnn = np.argmax(cnn_ens2.predict(X_sub_test), axis=1)\n",
    "rec_cnn = mt.recall_score(y_sub_test,yhat_cnn)\n",
    "acc_cnn = mt.accuracy_score(y_sub_test,yhat_cnn)\n",
    "print(\"Recall: \", rec_cnn)\n",
    "print(\"Accuracy: \", acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "#SVG(model_to_dot(cnn2_de).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "l2_lambda = 0.0001\n",
    "\n",
    "num_ensembles = 10\n",
    "input_holder = Input(shape=(w, h, 3))\n",
    "branches_le5 = []\n",
    "for _ in range(num_ensembles):\n",
    "    conv1 = Conv2D(filters=6,kernel_size=(5,5),\n",
    "                   input_shape = (img_wh,img_wh,1), \n",
    "                   padding='valid', \n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda))(input_holder)\n",
    "    max1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
    "    batch1 = BatchNormalization()(max1)\n",
    "    activ1 = Activation(\"sigmoid\")(batch1)\n",
    "\n",
    "    conv2 = Conv2D(filters=16,kernel_size=(5,5), \n",
    "                   padding='valid', \n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda))(activ1)\n",
    "    max2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
    "    batch2 = BatchNormalization()(max2)\n",
    "    activ2 = Activation(\"sigmoid\")(batch2)\n",
    "\n",
    "    conv3 = Conv2D(filters=120,kernel_size=(1,1), \n",
    "                   padding='valid', \n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=l2(l2_lambda))(activ2)\n",
    "\n",
    "\n",
    "    # add one layer on flattened output\n",
    "    #drop1 = Dropout(0.25)(max2) # add some dropout for regularization after conv layers\n",
    "    flat1 = Flatten()(conv3)\n",
    "    dense1 = Dense(128, \n",
    "                  activation='relu',\n",
    "                  kernel_initializer='he_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                )(flat1)\n",
    "    drop2 = Dropout(0.5)(dense1) # add some dropout for regularization, again!\n",
    "    dense2 = Dense(NUM_CLASSES, \n",
    "                  activation='sigmoid', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  kernel_regularizer=l2(l2_lambda)\n",
    "                 )(drop2)\n",
    "    branches_le5.append(dense2)\n",
    "\n",
    "# that's it, we just need to average the results\n",
    "ave_le5 = average(branches_le5)   \n",
    "\n",
    "\n",
    "cnn_le5 = Model(inputs=input_holder,outputs=ave_le5)\n",
    "\n",
    "# Let's train the model \n",
    "cnn_le5.compile(loss='binary_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "cnn_le5.fit_generator(datagen.flow(X_sub_train, y_sub_train_ohe, batch_size=128), \n",
    "                      steps_per_epoch=int(len(X_sub_train)/128), # how many generators to go through per epoch\n",
    "                      epochs=10, verbose=1,\n",
    "                      validation_data=(X_sub_test,y_sub_test_ohe),\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=4)]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2 \n",
    "l2_lambda = 0.0001\n",
    "img_wh = 32\n",
    "\n",
    "# Use Kaiming He to regularize ReLU layers: https://arxiv.org/pdf/1502.01852.pdf\n",
    "# Use Glorot/Bengio for linear/sigmoid/softmax: http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf \n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu')) # more compact syntax\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn.add(Dropout(0.25)) # add some dropout for regularization after conv layers\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, \n",
    "              activation='relu',\n",
    "              kernel_initializer='he_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "       ))\n",
    "cnn.add(Dropout(0.5)) # add some dropout for regularization, again!\n",
    "cnn.add(Dense(NUM_CLASSES, \n",
    "              activation='softmax', \n",
    "              kernel_initializer='glorot_uniform',\n",
    "              kernel_regularizer=l2(l2_lambda)\n",
    "             ))\n",
    "\n",
    "# Let's train the model \n",
    "cnn.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "              optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "cnn.fit_generator(datagen.flow(X_subtrain, y_train_ohe, batch_size=128), \n",
    "                  steps_per_epoch=int(len(X_train)/128), # how many generators to go through per epoch\n",
    "                  epochs=50, verbose=1,\n",
    "                  validation_data=(X_sub_test,y_test_ohe),\n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=2)]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
